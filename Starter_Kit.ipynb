{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Detectron2 Starter Kit",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GollyTicker/Food-Recognition-Challenge/blob/main/Starter_Kit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yt_yLzMyRHP8"
      },
      "source": [
        "![AIcrowd-Logo](https://raw.githubusercontent.com/AIcrowd/AIcrowd/master/app/assets/images/misc/aicrowd-horizontal.png)\n",
        "\n",
        "This dataset and notebook correspond to the [Food Recognition Challenge](https://www.aicrowd.com/challenges/food-recognition-challenge) being held on [AIcrowd](https://www.aicrowd.com/).\n",
        "\n",
        "<p align=\"right\"> Join the communty! <br><a href=\"https://discord.gg/GTckBMx\"><img src=\"https://img.shields.io/discord/657211973435392011?style=for-the-badge\" alt=\"chat on Discord\"></a>\n",
        "</p>\n",
        "\n",
        "# <center> üçï Food Recognition Challenge: Detectron2 starter kit </center>\n",
        "\n",
        "<center>This notebook aims to build a model for food detection and segmentation using <code>detectron2</code></center>\n",
        "\n",
        "# How to use this notebook? üìù\n",
        "1. **Copy the notebook**. This is a shared template and any edits you make here will not be saved. _You should copy it into your own drive folder._ For this, click the \"File\" menu (top-left), then \"Save a Copy in Drive\". You can edit your copy however you like.\n",
        "2. **Make a submission**. Run all the code in the notebook to get a feel of how the notebook and the submission process works.\n",
        "3. **Try tweaking the parameters**. If you are new to the problem, a great way to start is try tweaking the configuration flags, train your model and submit again.\n",
        "4. **Diving into the code**. When you submit via this notebook, we create a repository on [gitlab.aicrowd.com](https://gitlab.aicrowd.com). You can check the code we generated based on this notebook and directly make changes you want there!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqCwgApzqFK6"
      },
      "source": [
        "# Setup the notebook üõ†"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_embMQfcqIK5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06130d1f-04fb-47c2-b156-550077c7f4c4"
      },
      "source": [
        "!bash <(curl -sL https://gitlab.aicrowd.com/jyotish/food-recognition-challenge-detectron2-baseline/raw/master/utils/setup-colab.sh)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AIcrowd installer starting...\n",
            "Setting up the environment for you!\n",
            "‚öôÔ∏è Installing PyTorch...\n",
            "‚öôÔ∏è Installing COCO API...\n",
            "  Running command git clone -q https://github.com/cocodataset/cocoapi.git /tmp/pip-req-build-n74pv0xj\n",
            "‚öôÔ∏è Installing detectron...\n",
            "üóÑ Preparing the dataset for training...\n",
            "üóÑ Preparing the validation dataset...\n",
            "All set! üéâüçª\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDA1bgkg-8yu"
      },
      "source": [
        "# Configure static variables üìé"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6kEtMOl-8GO"
      },
      "source": [
        "class Paths:\n",
        "  DATASET_DIR = \"dataset\"\n",
        "  TRAIN_DATA_DIR = f\"{DATASET_DIR}/train\"\n",
        "  TRAIN_IMAGES_DIR = f\"{TRAIN_DATA_DIR}/images\"\n",
        "  TRAIN_ANNOTATIONS = f\"{TRAIN_DATA_DIR}/annotations.json\"\n",
        "  VAL_DATA_DIR = f\"{DATASET_DIR}/val\"\n",
        "  VAL_ANNOTATIONS = f\"{VAL_DATA_DIR}/annotations.json\"\n",
        "  VAL_IMAGES_DIR = f\"{VAL_DATA_DIR}/images\"\n",
        "\n",
        "\n",
        "class DatasetLabels:\n",
        "  TRAIN = \"dataset_train\"\n",
        "  VAL = \"dataset_val\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGt1_dNs_LFB"
      },
      "source": [
        "# Packages üóÉ\n",
        "\n",
        "Import here all the packages you need to define your model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOxxkvKI5jhA"
      },
      "source": [
        "import os\n",
        "from multiprocessing import Pool\n",
        "import json\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "from pycocotools.coco import COCO\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "from detectron2.data.datasets import register_coco_instances\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.utils.visualizer import ColorMode\n",
        "from detectron2.data import MetadataCatalog\n",
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "from detectron2.data import build_detection_test_loader\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.engine import DefaultTrainer\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.utils.events import get_event_storage\n",
        "from detectron2.engine import HookBase"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgc_ZDzmzyOE"
      },
      "source": [
        "# Loading the data üì≤"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xii1QDbCpZ0K"
      },
      "source": [
        "with open(Paths.TRAIN_ANNOTATIONS) as fp:\n",
        "  annotations = json.load(fp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7Yr5lfoAnwJ"
      },
      "source": [
        "## Helper functions to clean the dataset\n",
        "\n",
        "First, we will see if all the annotations in the dataset are properly aligned with the images. These helper functions will let us do that."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SstjAZ9UR6mk"
      },
      "source": [
        "image_dir = \"\"\n",
        "\n",
        "\n",
        "def validate_annotation(annotation):\n",
        "  \"\"\"Check the image dimensions and fix them if needed\n",
        "  \"\"\"\n",
        "  filepath = os.path.join(image_dir, annotation.get(\"file_name\"))\n",
        "  if not os.path.exists(filepath):\n",
        "    print(\"Skipping\", filepath)\n",
        "    return annotation\n",
        "  img = cv2.imread(filepath)\n",
        "  if img.shape[0] != annotation.get(\"height\") or img.shape[1] != annotation.get(\"width\"):\n",
        "    annotation[\"height\"], annotation[\"width\"] = annotation[\"width\"], annotation[\"height\"]\n",
        "  return annotation\n",
        "\n",
        "\n",
        "def clean_annotations(annotation_images):\n",
        "  \"\"\"Read the image dimensions and fix them in parallel\n",
        "  \"\"\"\n",
        "  annotated_images = []\n",
        "\n",
        "  with Pool() as p:\n",
        "    total_images = len(annotation_images)\n",
        "\n",
        "    with tqdm(total=total_images) as progress_bar:\n",
        "      for annotation in p.imap(validate_annotation, annotation_images):\n",
        "        annotated_images.append(annotation)\n",
        "        progress_bar.update(1)\n",
        "\n",
        "  return annotated_images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbxqgfj0Xd8Q"
      },
      "source": [
        "## Clean the training data üßπ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVAP3Ds09qxe"
      },
      "source": [
        "image_dir = Paths.TRAIN_IMAGES_DIR\n",
        "annotations[\"images\"] = clean_annotations(annotations.get(\"images\"))\n",
        "\n",
        "with open(Paths.TRAIN_ANNOTATIONS, \"w\") as fp:\n",
        "  json.dump(annotations, fp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZM_-xKcXhvH"
      },
      "source": [
        "## Clean the validation data üßπ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnFNbX9DX6Ci"
      },
      "source": [
        "image_dir = Paths.VAL_IMAGES_DIR\n",
        "\n",
        "with open(Paths.VAL_ANNOTATIONS) as fp:\n",
        "  validation_annotations = json.load(fp)\n",
        "\n",
        "validation_annotations[\"images\"] = clean_annotations(validation_annotations.get(\"images\"))\n",
        "\n",
        "with open(Paths.VAL_ANNOTATIONS, \"w\") as fp:\n",
        "  json.dump(validation_annotations, fp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ht-gFR2KbhjX"
      },
      "source": [
        "# Initialize detectron2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFhNKYKLXiYG"
      },
      "source": [
        "_ = setup_logger()\n",
        "\n",
        "register_coco_instances(DatasetLabels.TRAIN, {}, Paths.TRAIN_ANNOTATIONS, Paths.TRAIN_IMAGES_DIR)\n",
        "register_coco_instances(DatasetLabels.VAL, {}, Paths.VAL_ANNOTATIONS, Paths.VAL_IMAGES_DIR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEn4diGaA_ph"
      },
      "source": [
        "# Build your Model üè≠\n",
        "\n",
        "We will use Mask R-CNN to generate the segmentation masks for the food items üåØ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYqXect1M4Jz"
      },
      "source": [
        "## Configure detectron2\n",
        "\n",
        "Detectron2 has a variety of Instance Segmentation Models. We will use the zoo model with Mask RCNN + ResNet 50. If you want to try other models, you can find them [here]((https://github.com/facebookresearch/detectron2)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_q2fu8wXikF"
      },
      "source": [
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
        "\n",
        "cfg.DATASETS.TRAIN = (DatasetLabels.TRAIN,)\n",
        "cfg.DATASETS.TEST = ()\n",
        "cfg.DATALOADER.NUM_WORKERS = 2\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 273  # Number of output classes\n",
        "\n",
        "cfg.OUTPUT_DIR = \"outputs\"\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzaHmc0IPAIZ"
      },
      "source": [
        "## Load the pre-trained weights "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWmZ6VySPC14"
      },
      "source": [
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
        "cfg.SOLVER.IMS_PER_BATCH = 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wg5Ra2qzO5YV"
      },
      "source": [
        "## Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fj5HPBMVO-I3"
      },
      "source": [
        "cfg.SOLVER.BASE_LR = 0.00025  # Learning Rate\n",
        "cfg.SOLVER.MAX_ITER = 20000  # MAx Iterations\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128  # Batch Size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EER82dGmQGS9"
      },
      "source": [
        "# Train the model üöÇ\n",
        "\n",
        "We will setup tensorboard to check the performance of the model while it is training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMMmjhlO62Pj"
      },
      "source": [
        "## Setting up Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMOcJUcmfQI8"
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6E_Np0qn64uM"
      },
      "source": [
        "## Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZS5IZOx5XjDm"
      },
      "source": [
        "trainer = DefaultTrainer(cfg) \n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GBGSt63QZf1"
      },
      "source": [
        "# Evaluating the model üß™\n",
        "\n",
        "We will check the performance of our model on the validation dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BC0EzphvkslK"
      },
      "source": [
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5   # set the testing threshold for this model\n",
        "cfg.DATASETS.TEST = (DatasetLabels.VAL, )\n",
        "predictor = DefaultPredictor(cfg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5VkmUr1Qlyj"
      },
      "source": [
        "## Generate predictions on validation data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrfk7SynXjbV"
      },
      "source": [
        "evaluator = COCOEvaluator(DatasetLabels.VAL, cfg, False, output_dir=cfg.OUTPUT_DIR)\n",
        "data_loader = build_detection_test_loader(cfg, DatasetLabels.VAL)\n",
        "results = inference_on_dataset(predictor.model, data_loader, evaluator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNb_H5L-xX6d"
      },
      "source": [
        "## Visualizing the results üëì\n",
        "\n",
        "Numbers are good, but visualizations are better!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Gr_8OPtfyja"
      },
      "source": [
        "metadata = MetadataCatalog.get(DatasetLabels.VAL)\n",
        "\n",
        "# Load the training annotations if not loaded\n",
        "if not validation_annotations:\n",
        "  with open(Paths.VAL_ANNOTATIONS) as json_file:\n",
        "      annotations = json.load(json_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eXHZzn0S4Dp"
      },
      "source": [
        "## Check the predictions\n",
        "\n",
        "**Note:** If you are not able to see segmentation masks on the images, that generally means that the model didn't predict a mask for that image. You can verify this by doing\n",
        "\n",
        "```python\n",
        "predictions = predictor(img)\n",
        "print(predictions)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1XMJcWLS7rX"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['figure.dpi'] = 180\n",
        "\n",
        "\n",
        "# Visualize some random images\n",
        "for i in range(8):\n",
        "  image_filename = np.random.choice(validation_annotations.get(\"images\")).get(\"file_name\")\n",
        "  image_filename = os.path.join(Paths.VAL_IMAGES_DIR, image_filename)\n",
        "\n",
        "  img = cv2.imread(image_filename)\n",
        "  predictions = predictor(img)\n",
        "\n",
        "  v = Visualizer(img[:, :, ::-1],\n",
        "    metadata=metadata, \n",
        "    scale=0.5, \n",
        "    # instance_mode=ColorMode.IMAGE_BW\n",
        "  )\n",
        "  annotated_image = v.draw_instance_predictions(predictions[\"instances\"].to(\"cpu\"))\n",
        "\n",
        "  plt.subplot(2, 4, i+1)\n",
        "  plt.axis('off')\n",
        "  plt.imshow(annotated_image.get_image())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFAos6c6DGcx"
      },
      "source": [
        "# A note on class ID mappings\n",
        "\n",
        "Here is how the category object looks like\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"id\": 2578,\n",
        "  \"name\": \"water\",\n",
        "  \"name_readable\": \"Water\",\n",
        "  \"supercategory\": \"food\"\n",
        "}\n",
        "```\n",
        "\n",
        "Detectron2 usually maps the category IDs to contiguous numbers. For example, consider the following categories,\n",
        "\n",
        "```json\n",
        "[\n",
        "  {\n",
        "    \"id\": 2578,\n",
        "    \"name\": \"water\",\n",
        "    \"name_readable\": \"Water\",\n",
        "    \"supercategory\": \"food\"\n",
        "  },\n",
        "  {\n",
        "    \"id\": 1157,\n",
        "    \"name\": \"pear\",\n",
        "    \"name_readable\": \"Pear\",\n",
        "    \"supercategory\": \"food\"\n",
        "  },\n",
        "  {\n",
        "    \"id\": 2022,\n",
        "    \"name\": \"egg\",\n",
        "    \"name_readable\": \"Egg\",\n",
        "    \"supercategory\": \"food\"\n",
        "  }\n",
        "]\n",
        "```\n",
        "\n",
        "Detectron internally maps these categories to something like\n",
        "\n",
        "```json\n",
        "{\n",
        "  0: 2578, # detectron_id: actual_class_id\n",
        "  1: 1157,\n",
        "  2: 2022\n",
        "}\n",
        "```\n",
        "\n",
        "So, when your model detects water, the prediction class ID that your model returns will be `0` and **not** `2578` . You should make sure to map these detectron IDs to their original actual class IDs for your submission to get scored properly.\n",
        "\n",
        "Here's how you can get this mapping."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O98OLrwV7IPO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09d28337-fb76-4ef8-8823-8ace13626a8f"
      },
      "source": [
        "coco_api = COCO(Paths.TRAIN_ANNOTATIONS)\n",
        "\n",
        "category_ids = sorted(coco_api.getCatIds())\n",
        "categories = coco_api.loadCats(category_ids)\n",
        "\n",
        "class_to_category = { int(class_id): int(category_id) for class_id, category_id in enumerate(category_ids) }\n",
        "\n",
        "with open(\"class_to_category.json\", \"w\") as fp:\n",
        "  json.dump(class_to_category, fp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=2.93s)\n",
            "creating index...\n",
            "index created!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fThCV_4uAm4"
      },
      "source": [
        "# Ready? Submit to AIcrowd üöÄ\n",
        "\n",
        "Now you can submit the trained model to AIcrowd!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcaSuCpiMVvb"
      },
      "source": [
        "## Submission configuration ‚öôÔ∏è"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEPtkV57KC54"
      },
      "source": [
        "aicrowd_submission = {\n",
        "    \"author\": \"<your name>\",\n",
        "    \"username\": \"<your aicrowd username>\",\n",
        "    \"description\": \"initial submission with detectron\",\n",
        "    \"debug\": False,\n",
        "    \"model_path\": \"outputs/model_final.pth\",\n",
        "    \"model_type\": \"model_zoo\",\n",
        "    \"model_config_file\": \"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\",\n",
        "    \"detectron_model_config\": {\n",
        "      \"ROI_HEADS\": {\n",
        "        \"SCORE_THRESH_TEST\": 0.5,\n",
        "        \"NUM_CLASSES\": 273\n",
        "      }\n",
        "    }\n",
        "}\n",
        "\n",
        "aicrowd_submission[\"description\"] = aicrowd_submission[\"description\"].replace(\" \", \"-\")\n",
        "with open(\"aicrowd.json\", \"w\") as fp:\n",
        "  json.dump(aicrowd_submission, fp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PKKwhlkKCfc"
      },
      "source": [
        "## Submit to AIcrowd\n",
        "\n",
        "**Note:** We will create an SSH key on your google drive. This key will be used to identify you on gitlab.aicrowd.com."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFB2X_nkrGU5"
      },
      "source": [
        "!bash <(curl -sL https://gitlab.aicrowd.com/jyotish/food-recognition-challenge-detectron2-baseline/raw/master/utils/submit-colab.sh)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrEBfu7rPHir"
      },
      "source": [
        "# üìé Important Links\n",
        "\n",
        "* üí™ Challenge Page: https://www.aicrowd.com/challenges/food-recognition-challenge\n",
        "* üó£ Discussion Forum: https://discourse.aicrowd.com/c/food-recognition-challenge\n",
        "* üèÜ Leaderboard: https://www.aicrowd.com/challenges/food-recognition-challenge/leaderboards  "
      ]
    }
  ]
}